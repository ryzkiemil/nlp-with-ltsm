{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "nlp news article with lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cri21ncRsK8s"
      },
      "source": [
        "# Klasifikasi Berita bad, good, neutral menggunakan LSTM\n",
        "Ryzki perdana emil 11031330039"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxPN6mD6sK8w"
      },
      "source": [
        "### Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9J56IElsK8w"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCF0sCrisK8x",
        "outputId": "89af0f75-6491-4662-d8f3-f3d6540cd961"
      },
      "source": [
        "#import data dari\n",
        "df = pd.read_csv('E:/emil/code/data/dataset.csv')\n",
        "print(len(df))\n",
        "df.category.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4055\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "neutral    1668\n",
              "bad        1278\n",
              "good       1109\n",
              "Name: category, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqpMHtUFsK8y",
        "outputId": "79e42565-5706-4524-a9d6-c004e2df9e76"
      },
      "source": [
        "#mengambil sampel data\n",
        "def sampel_data(data,n):\n",
        "    if ndata==0:\n",
        "      return data.sample(frac=1).reset_index(drop=True)\n",
        "    n = round(n/3)\n",
        "    data.sample(frac=1).reset_index(drop=True)\n",
        "    data1 = df.loc[df['category'] == 'bad']                       # menampung data berlabel bad\n",
        "    data2 = df.loc[df['category'] == 'good']                      # menampung data berlabel good\n",
        "    data3 = df.loc[df['category'] == 'neutral']                   # menampung data berlabel neutral\n",
        "    data1 = data1.sample(n)                                       # mengambil sampel data bad sebanyak n\n",
        "    data2 = data2.sample(n)                                       # mengambil sampel data good sebanyak n\n",
        "    data3 = data3.sample(n)                                       # mengambil sampel data neutral sebanyak n\n",
        "    frames = [data1, data2, data3]                                # membuat dataframe baru berisi sample data \n",
        "    data = pd.concat(frames)                                      # menggabungkan sampel data bad,good dan neutral\n",
        "    return data.sample(frac=1).reset_index(drop=True)             # mengacak seluruh data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRtYumn0uCnA"
      },
      "source": [
        "ndata = 500                                                       # masukan jumlah data yang akan dipakai (isi dengan '0' jika ingin menggunakan semua data)\n",
        "data = sampel_data(df,ndata)\n",
        "print(len(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGvPUvAnsK8y"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIZv-QsNsK8z"
      },
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDnjXoURsK8z",
        "outputId": "84b6da38-8359-43ba-a247-3806befc8575"
      },
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "stemmer=PorterStemmer()\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = text.lower() # casefolding\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # menghapus punctuation\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # menghapus punctuation\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # stopword removal\n",
        "    text = ' '.join(stemmer.stem(word) for word in text.split()) # Stemming\n",
        "    return text\n",
        "data['text'] = data['text'].apply(clean_text)\n",
        "data['text'] = data['text'].str.replace('\\d+', '')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good</td>\n",
              "      <td>ad sale boost time warner profit quarterli pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>good</td>\n",
              "      <td>itali get econom action plan italian prime min...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>good</td>\n",
              "      <td>wmc profit amid bid critic australian mine fir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "      <td>commodor find new leas life oncefam commodor c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>bmw reveal new model pipelin bmw prepar enter ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category                                               text\n",
              "0     good  ad sale boost time warner profit quarterli pro...\n",
              "1     good  itali get econom action plan italian prime min...\n",
              "2     good  wmc profit amid bid critic australian mine fir...\n",
              "3  neutral  commodor find new leas life oncefam commodor c...\n",
              "4  neutral  bmw reveal new model pipelin bmw prepar enter ..."
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbfQ1xsqsK80"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV3JRfwCsK80"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QycNv8NwsK81",
        "outputId": "4778ace3-0b47-40a4-bd0d-3d30517809d9"
      },
      "source": [
        "# fungsi ini menerima input seluruh text dalam dataset dan memberi output jumlah kata unique\n",
        "def counter_word(text):\n",
        "    count = Counter()\n",
        "    for i in text.values:\n",
        "        for word in i.split():\n",
        "            count[word] += 1\n",
        "    return count\n",
        "\n",
        "counter = counter_word(data.text) # apply fungsi counter word\n",
        "num_words = len(counter)\n",
        "max_length = 400\n",
        "num_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10021"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cAuTVHJsK81"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ito_V_88sK81",
        "outputId": "88c77303-7cfd-4729-90d6-b3c4c63d5236"
      },
      "source": [
        "MAX_NB_WORDS = 50000 # jumlah kata yang akan digunakan\n",
        "MAX_SEQUENCE_LENGTH = 500 # jumlah kata dalam satu sekuen/satu row data\n",
        "EMBEDDING_DIM = 50 # jumlah neuron dalam tiap layer\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True) # inisiasi tokenizer\n",
        "tokenizer.fit_on_texts(data['text'].values) # inisiasi tokenizer\n",
        "word_index = tokenizer.word_index # membuat indeks dari kata unique\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10016 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emnHIrl_sK82"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axEANEn9sK82",
        "outputId": "ffcd9a26-3a64-4e67-bfc7-0bb8c2783e65"
      },
      "source": [
        "text = tokenizer.texts_to_sequences(data['text'].values) # data sequencing\n",
        "text = pad_sequences(text, maxlen=MAX_SEQUENCE_LENGTH) # padding the sequences\n",
        "label = pd.get_dummies(data['category']).values # variabel baru untuk menampung label dari data\n",
        "print('Shape dari label tensor:', label.shape)\n",
        "print('Shape dari data tensor:', text.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape dari label tensor: (501, 3)\n",
            "Shape dari data tensor: (501, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyXfpp8nsK83"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THJJK3WysK83"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "EKxEt3jGsK83",
        "outputId": "1feb8c40-6361-438b-df35-2a0717143eaf"
      },
      "source": [
        "# inisiasi variabel input sequensial neural network\n",
        "num_folds = 10\n",
        "no_epochs = 40\n",
        "batch_size = 64\n",
        "\n",
        "# inisiasi variabel penampung akurasi dan loss untuk evaluasi\n",
        "plot_acc_per_fold = pd.DataFrame()\n",
        "plot_loss_per_fold = pd.DataFrame()\n",
        "plot_val_acc_per_fold = pd.DataFrame()\n",
        "plot_val_loss_per_fold = pd.DataFrame()\n",
        "val_acc_per_fold = []\n",
        "val_loss_per_fold = []\n",
        "\n",
        "# inisiasi kfold\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "fold_no = 1\n",
        "\n",
        "# apply kfold\n",
        "for train, test in kfold.split(text, label):\n",
        "    \n",
        "    # Rancangan model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
        "    model.add(LSTM(50))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "    model.add(Dropout(0.35))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    \n",
        "    # Apply model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # Hasil evaluasi\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "    \n",
        "    # Fit data to model\n",
        "    history = model.fit(text[train], label[train],\n",
        "                        validation_data = (text[test], label[test]),\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=no_epochs)\n",
        "    \n",
        "    # menyimpan history tiap fold\n",
        "    plot_acc_per_fold[str(fold_no)] = history.history['accuracy']\n",
        "    plot_val_acc_per_fold[str(fold_no)] = history.history['val_accuracy']\n",
        "    plot_loss_per_fold[str(fold_no)] = history.history['loss']\n",
        "    plot_val_loss_per_fold[str(fold_no)] = history.history['val_loss']\n",
        "    \n",
        "    # pembuatan metriks evaluasi\n",
        "    scores = model.evaluate(text[test], label[test], verbose=0)\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "    val_acc_per_fold.append(scores[1] * 100)\n",
        "    val_loss_per_fold.append(scores[0])\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1\n",
        "\n",
        "# == meanmpilkan akurasi tiap fold dan rata-rata seluruhnya ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(val_acc_per_fold)):\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'> Fold {i+1} - Loss: {val_loss_per_fold[i]} - Accuracy: {val_acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(val_acc_per_fold)} (+- {np.std(val_acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(val_loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Train on 450 samples, validate on 51 samples\n",
            "Epoch 1/40\n",
            "450/450 [==============================] - 6s 13ms/step - loss: 1.0992 - accuracy: 0.3200 - val_loss: 1.0995 - val_accuracy: 0.3333\n",
            "Epoch 2/40\n",
            "450/450 [==============================] - 4s 10ms/step - loss: 1.0938 - accuracy: 0.4644 - val_loss: 1.0980 - val_accuracy: 0.3529\n",
            "Epoch 3/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 1.0852 - accuracy: 0.5689 - val_loss: 1.0979 - val_accuracy: 0.3725\n",
            "Epoch 4/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 1.0669 - accuracy: 0.6111 - val_loss: 1.0954 - val_accuracy: 0.3529\n",
            "Epoch 5/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 1.0146 - accuracy: 0.7711 - val_loss: 1.6181 - val_accuracy: 0.3333\n",
            "Epoch 6/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 1.0052 - accuracy: 0.7400 - val_loss: 1.0582 - val_accuracy: 0.4510\n",
            "Epoch 7/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 0.8356 - accuracy: 0.9222 - val_loss: 1.0449 - val_accuracy: 0.4510\n",
            "Epoch 8/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 0.6978 - accuracy: 0.9422 - val_loss: 1.0237 - val_accuracy: 0.4706\n",
            "Epoch 9/40\n",
            "450/450 [==============================] - 5s 11ms/step - loss: 0.4780 - accuracy: 0.9556 - val_loss: 1.0189 - val_accuracy: 0.5294\n",
            "Epoch 10/40\n",
            "450/450 [==============================] - 5s 11ms/step - loss: 0.2468 - accuracy: 0.9667 - val_loss: 1.1527 - val_accuracy: 0.4706\n",
            "Epoch 11/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 0.1310 - accuracy: 0.9733 - val_loss: 1.1453 - val_accuracy: 0.4902\n",
            "Epoch 12/40\n",
            "450/450 [==============================] - 5s 12ms/step - loss: 0.0824 - accuracy: 0.9933 - val_loss: 1.0954 - val_accuracy: 0.5294\n",
            "Epoch 13/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 0.0520 - accuracy: 0.9933 - val_loss: 1.1921 - val_accuracy: 0.5294\n",
            "Epoch 14/40\n",
            "450/450 [==============================] - 6s 12ms/step - loss: 0.0405 - accuracy: 0.9933 - val_loss: 1.3080 - val_accuracy: 0.5098\n",
            "Epoch 15/40\n",
            "450/450 [==============================] - 5s 11ms/step - loss: 0.0314 - accuracy: 0.9933 - val_loss: 1.4591 - val_accuracy: 0.5098\n",
            "Epoch 16/40\n",
            "450/450 [==============================] - 5s 12ms/step - loss: 0.0221 - accuracy: 0.9956 - val_loss: 1.5752 - val_accuracy: 0.5098\n",
            "Epoch 17/40\n",
            "450/450 [==============================] - 5s 12ms/step - loss: 0.0217 - accuracy: 0.9956 - val_loss: 1.6941 - val_accuracy: 0.5098\n",
            "Epoch 18/40\n",
            "450/450 [==============================] - 6s 13ms/step - loss: 0.0191 - accuracy: 0.9956 - val_loss: 1.8423 - val_accuracy: 0.5098\n",
            "Epoch 19/40\n",
            "450/450 [==============================] - 5s 11ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 1.8724 - val_accuracy: 0.5098\n",
            "Epoch 20/40\n",
            "450/450 [==============================] - 5s 11ms/step - loss: 0.0176 - accuracy: 0.9956 - val_loss: 1.9364 - val_accuracy: 0.5098\n",
            "Epoch 21/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 1.9027 - val_accuracy: 0.5294\n",
            "Epoch 22/40\n",
            "450/450 [==============================] - 5s 11ms/step - loss: 0.0309 - accuracy: 0.9956 - val_loss: 1.7555 - val_accuracy: 0.4902\n",
            "Epoch 23/40\n",
            "450/450 [==============================] - 5s 11ms/step - loss: 0.0576 - accuracy: 0.9867 - val_loss: 1.8304 - val_accuracy: 0.4314\n",
            "Epoch 24/40\n",
            "450/450 [==============================] - 6s 13ms/step - loss: 0.0564 - accuracy: 0.9911 - val_loss: 1.4286 - val_accuracy: 0.4706\n",
            "Epoch 25/40\n",
            "450/450 [==============================] - 6s 14ms/step - loss: 0.0414 - accuracy: 0.9956 - val_loss: 1.2935 - val_accuracy: 0.4706\n",
            "Epoch 26/40\n",
            "450/450 [==============================] - 5s 11ms/step - loss: 0.0413 - accuracy: 0.9956 - val_loss: 1.3251 - val_accuracy: 0.3922\n",
            "Epoch 27/40\n",
            "450/450 [==============================] - 5s 11ms/step - loss: 0.0383 - accuracy: 0.9956 - val_loss: 1.3652 - val_accuracy: 0.4510\n",
            "Epoch 28/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 0.0249 - accuracy: 0.9956 - val_loss: 1.4286 - val_accuracy: 0.4706\n",
            "Epoch 29/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 0.0260 - accuracy: 0.9956 - val_loss: 1.4931 - val_accuracy: 0.4510\n",
            "Epoch 30/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 0.0205 - accuracy: 0.9956 - val_loss: 1.5481 - val_accuracy: 0.4314\n",
            "Epoch 31/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 0.0205 - accuracy: 0.9956 - val_loss: 1.5865 - val_accuracy: 0.4118\n",
            "Epoch 32/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 0.0202 - accuracy: 0.9956 - val_loss: 1.6018 - val_accuracy: 0.4118\n",
            "Epoch 33/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 1.5822 - val_accuracy: 0.4510\n",
            "Epoch 34/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 0.0192 - accuracy: 0.9956 - val_loss: 1.6370 - val_accuracy: 0.4706\n",
            "Epoch 35/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 1.7714 - val_accuracy: 0.4706\n",
            "Epoch 36/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 1.6244 - val_accuracy: 0.4314\n",
            "Epoch 37/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 1.5421 - val_accuracy: 0.4902\n",
            "Epoch 38/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 1.6230 - val_accuracy: 0.4902\n",
            "Epoch 39/40\n",
            "450/450 [==============================] - 5s 10ms/step - loss: 0.0146 - accuracy: 0.9933 - val_loss: 1.5985 - val_accuracy: 0.4706\n",
            "Epoch 40/40\n",
            "450/450 [==============================] - 5s 11ms/step - loss: 0.0115 - accuracy: 0.9956 - val_loss: 1.6283 - val_accuracy: 0.4902\n",
            "Score for fold 1: loss of 1.628326647421893; accuracy of 49.01960790157318%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Train on 451 samples, validate on 50 samples\n",
            "Epoch 1/40\n",
            "451/451 [==============================] - 6s 13ms/step - loss: 1.0987 - accuracy: 0.3237 - val_loss: 1.0963 - val_accuracy: 0.4600\n",
            "Epoch 2/40\n",
            "451/451 [==============================] - 4s 9ms/step - loss: 1.0937 - accuracy: 0.4900 - val_loss: 1.0947 - val_accuracy: 0.4800\n",
            "Epoch 3/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 1.0864 - accuracy: 0.5787 - val_loss: 1.0914 - val_accuracy: 0.3800\n",
            "Epoch 4/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 1.0679 - accuracy: 0.6475 - val_loss: 1.0807 - val_accuracy: 0.3800\n",
            "Epoch 5/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.9977 - accuracy: 0.6918 - val_loss: 0.9951 - val_accuracy: 0.5200\n",
            "Epoch 6/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 1.1411 - accuracy: 0.5188 - val_loss: 0.9701 - val_accuracy: 0.5400\n",
            "Epoch 7/40\n",
            "451/451 [==============================] - 6s 13ms/step - loss: 0.7964 - accuracy: 0.7650 - val_loss: 1.0237 - val_accuracy: 0.3600\n",
            "Epoch 8/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.6908 - accuracy: 0.8027 - val_loss: 0.9212 - val_accuracy: 0.4800\n",
            "Epoch 9/40\n",
            "451/451 [==============================] - 6s 13ms/step - loss: 0.5657 - accuracy: 0.8537 - val_loss: 0.8673 - val_accuracy: 0.5400\n",
            "Epoch 10/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.5254 - accuracy: 0.8271 - val_loss: 0.8929 - val_accuracy: 0.5400\n",
            "Epoch 11/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.4324 - accuracy: 0.8736 - val_loss: 0.8821 - val_accuracy: 0.6000\n",
            "Epoch 12/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.3653 - accuracy: 0.9157 - val_loss: 0.9033 - val_accuracy: 0.5800\n",
            "Epoch 13/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.3201 - accuracy: 0.9667 - val_loss: 1.0339 - val_accuracy: 0.5400\n",
            "Epoch 14/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.3089 - accuracy: 0.9667 - val_loss: 1.0310 - val_accuracy: 0.5400\n",
            "Epoch 15/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.2043 - accuracy: 0.9800 - val_loss: 1.0525 - val_accuracy: 0.5600\n",
            "Epoch 16/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.1213 - accuracy: 0.9889 - val_loss: 1.0417 - val_accuracy: 0.6000\n",
            "Epoch 17/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0801 - accuracy: 0.9956 - val_loss: 1.0917 - val_accuracy: 0.5400\n",
            "Epoch 18/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0541 - accuracy: 0.9933 - val_loss: 1.2048 - val_accuracy: 0.5400\n",
            "Epoch 19/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0444 - accuracy: 0.9933 - val_loss: 1.2298 - val_accuracy: 0.5400\n",
            "Epoch 20/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0381 - accuracy: 0.9933 - val_loss: 1.1802 - val_accuracy: 0.5600\n",
            "Epoch 21/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0314 - accuracy: 0.9956 - val_loss: 1.2251 - val_accuracy: 0.5600\n",
            "Epoch 22/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0300 - accuracy: 0.9956 - val_loss: 1.4116 - val_accuracy: 0.5400\n",
            "Epoch 23/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0258 - accuracy: 0.9956 - val_loss: 1.5465 - val_accuracy: 0.5200\n",
            "Epoch 24/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 1.5415 - val_accuracy: 0.5400\n",
            "Epoch 25/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 0.0227 - accuracy: 0.9956 - val_loss: 1.5406 - val_accuracy: 0.5200\n",
            "Epoch 26/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0167 - accuracy: 0.9956 - val_loss: 1.6417 - val_accuracy: 0.5200\n",
            "Epoch 27/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0188 - accuracy: 0.9956 - val_loss: 1.5894 - val_accuracy: 0.5600\n",
            "Epoch 28/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0182 - accuracy: 0.9956 - val_loss: 1.4897 - val_accuracy: 0.5600\n",
            "Epoch 29/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 1.5779 - val_accuracy: 0.5200\n",
            "Epoch 30/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 1.9557 - val_accuracy: 0.5600\n",
            "Epoch 31/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0179 - accuracy: 0.9956 - val_loss: 1.6724 - val_accuracy: 0.5000\n",
            "Epoch 32/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 1.5011 - val_accuracy: 0.5400\n",
            "Epoch 33/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 1.4661 - val_accuracy: 0.5400\n",
            "Epoch 34/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0174 - accuracy: 0.9933 - val_loss: 1.4907 - val_accuracy: 0.5600\n",
            "Epoch 35/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 1.5141 - val_accuracy: 0.5400\n",
            "Epoch 36/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0136 - accuracy: 0.9933 - val_loss: 1.5899 - val_accuracy: 0.5400\n",
            "Epoch 37/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0108 - accuracy: 0.9956 - val_loss: 1.4511 - val_accuracy: 0.5600\n",
            "Epoch 38/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0178 - accuracy: 0.9956 - val_loss: 1.3880 - val_accuracy: 0.5800\n",
            "Epoch 39/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0231 - accuracy: 0.9956 - val_loss: 1.3583 - val_accuracy: 0.5800\n",
            "Epoch 40/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0222 - accuracy: 0.9978 - val_loss: 1.3687 - val_accuracy: 0.5800\n",
            "Score for fold 2: loss of 1.3687478399276733; accuracy of 57.999998331069946%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Train on 451 samples, validate on 50 samples\n",
            "Epoch 1/40\n",
            "451/451 [==============================] - 6s 13ms/step - loss: 1.0987 - accuracy: 0.3326 - val_loss: 1.0986 - val_accuracy: 0.4000\n",
            "Epoch 2/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 1.0932 - accuracy: 0.4701 - val_loss: 1.0987 - val_accuracy: 0.3000\n",
            "Epoch 3/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 1.0834 - accuracy: 0.5521 - val_loss: 1.0883 - val_accuracy: 0.5000\n",
            "Epoch 4/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 1.0651 - accuracy: 0.6563 - val_loss: 1.0641 - val_accuracy: 0.6000\n",
            "Epoch 5/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 0.9712 - accuracy: 0.7472 - val_loss: 0.9767 - val_accuracy: 0.5600\n",
            "Epoch 6/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 1.2778 - accuracy: 0.5055 - val_loss: 0.8853 - val_accuracy: 0.6600\n",
            "Epoch 7/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.8337 - accuracy: 0.7716 - val_loss: 0.9626 - val_accuracy: 0.6000\n",
            "Epoch 8/40\n",
            "451/451 [==============================] - 6s 12ms/step - loss: 0.7704 - accuracy: 0.8049 - val_loss: 0.9087 - val_accuracy: 0.6400\n",
            "Epoch 9/40\n",
            "451/451 [==============================] - 6s 14ms/step - loss: 0.6562 - accuracy: 0.8182 - val_loss: 0.8324 - val_accuracy: 0.7000\n",
            "Epoch 10/40\n",
            "451/451 [==============================] - 6s 13ms/step - loss: 0.5293 - accuracy: 0.8670 - val_loss: 0.8044 - val_accuracy: 0.6600\n",
            "Epoch 11/40\n",
            "451/451 [==============================] - 7s 15ms/step - loss: 0.3763 - accuracy: 0.9224 - val_loss: 0.7338 - val_accuracy: 0.7400\n",
            "Epoch 12/40\n",
            "451/451 [==============================] - 6s 13ms/step - loss: 0.2328 - accuracy: 0.9601 - val_loss: 0.7413 - val_accuracy: 0.6600\n",
            "Epoch 13/40\n",
            "451/451 [==============================] - 7s 16ms/step - loss: 0.1480 - accuracy: 0.9756 - val_loss: 0.9241 - val_accuracy: 0.7400\n",
            "Epoch 14/40\n",
            "451/451 [==============================] - 7s 15ms/step - loss: 0.0776 - accuracy: 0.9911 - val_loss: 0.9022 - val_accuracy: 0.6600\n",
            "Epoch 15/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0668 - accuracy: 0.9867 - val_loss: 1.0516 - val_accuracy: 0.6800\n",
            "Epoch 16/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0496 - accuracy: 0.9956 - val_loss: 1.1304 - val_accuracy: 0.6800\n",
            "Epoch 17/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0343 - accuracy: 0.9956 - val_loss: 1.2349 - val_accuracy: 0.6400\n",
            "Epoch 18/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0310 - accuracy: 0.9956 - val_loss: 1.3546 - val_accuracy: 0.6800\n",
            "Epoch 19/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0242 - accuracy: 0.9956 - val_loss: 1.3683 - val_accuracy: 0.6600\n",
            "Epoch 20/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0294 - accuracy: 0.9956 - val_loss: 1.4385 - val_accuracy: 0.6400\n",
            "Epoch 21/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.0281 - accuracy: 0.9956 - val_loss: 1.4626 - val_accuracy: 0.6600\n",
            "Epoch 22/40\n",
            "451/451 [==============================] - 6s 13ms/step - loss: 0.0207 - accuracy: 0.9956 - val_loss: 1.5930 - val_accuracy: 0.6600\n",
            "Epoch 23/40\n",
            "451/451 [==============================] - 7s 15ms/step - loss: 0.0223 - accuracy: 0.9956 - val_loss: 1.6090 - val_accuracy: 0.6600\n",
            "Epoch 24/40\n",
            "451/451 [==============================] - 6s 14ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 1.6142 - val_accuracy: 0.6600\n",
            "Epoch 25/40\n",
            "451/451 [==============================] - 6s 12ms/step - loss: 0.0224 - accuracy: 0.9956 - val_loss: 1.6317 - val_accuracy: 0.6600\n",
            "Epoch 26/40\n",
            "451/451 [==============================] - 6s 14ms/step - loss: 0.0190 - accuracy: 0.9956 - val_loss: 1.5587 - val_accuracy: 0.6800\n",
            "Epoch 27/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.0206 - accuracy: 0.9956 - val_loss: 1.5175 - val_accuracy: 0.6800\n",
            "Epoch 28/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 1.7923 - val_accuracy: 0.6600\n",
            "Epoch 29/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0169 - accuracy: 0.9956 - val_loss: 1.6738 - val_accuracy: 0.6800\n",
            "Epoch 30/40\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 1.7050 - val_accuracy: 0.6800\n",
            "Epoch 31/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0198 - accuracy: 0.9978 - val_loss: 1.6396 - val_accuracy: 0.7000\n",
            "Epoch 32/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 1.5505 - val_accuracy: 0.6600\n",
            "Epoch 33/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.0161 - accuracy: 0.9956 - val_loss: 1.6310 - val_accuracy: 0.6800\n",
            "Epoch 34/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 1.7385 - val_accuracy: 0.6600\n",
            "Epoch 35/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 1.7210 - val_accuracy: 0.6800\n",
            "Epoch 36/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 1.6364 - val_accuracy: 0.7000\n",
            "Epoch 37/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0181 - accuracy: 0.9911 - val_loss: 1.7843 - val_accuracy: 0.6800\n",
            "Epoch 38/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0102 - accuracy: 0.9956 - val_loss: 1.7586 - val_accuracy: 0.6800\n",
            "Epoch 39/40\n",
            "451/451 [==============================] - 6s 13ms/step - loss: 0.0102 - accuracy: 0.9933 - val_loss: 1.8168 - val_accuracy: 0.6800\n",
            "Epoch 40/40\n",
            "451/451 [==============================] - 6s 13ms/step - loss: 0.0137 - accuracy: 0.9933 - val_loss: 1.7022 - val_accuracy: 0.6800\n",
            "Score for fold 3: loss of 1.7021769285202026; accuracy of 68.00000071525574%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Train on 451 samples, validate on 50 samples\n",
            "Epoch 1/40\n",
            "451/451 [==============================] - 7s 15ms/step - loss: 1.0981 - accuracy: 0.3548 - val_loss: 1.0992 - val_accuracy: 0.2800\n",
            "Epoch 2/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 1.0923 - accuracy: 0.4568 - val_loss: 1.0998 - val_accuracy: 0.2600\n",
            "Epoch 3/40\n",
            "451/451 [==============================] - 6s 13ms/step - loss: 1.0805 - accuracy: 0.5898 - val_loss: 1.0952 - val_accuracy: 0.4200\n",
            "Epoch 4/40\n",
            "451/451 [==============================] - 6s 14ms/step - loss: 1.0518 - accuracy: 0.7627 - val_loss: 1.0740 - val_accuracy: 0.4600\n",
            "Epoch 5/40\n",
            "451/451 [==============================] - 6s 13ms/step - loss: 0.9473 - accuracy: 0.7162 - val_loss: 1.0546 - val_accuracy: 0.4800\n",
            "Epoch 6/40\n",
            "451/451 [==============================] - 6s 14ms/step - loss: 0.8610 - accuracy: 0.8182 - val_loss: 1.0474 - val_accuracy: 0.4400\n",
            "Epoch 7/40\n",
            "451/451 [==============================] - 6s 13ms/step - loss: 0.7714 - accuracy: 0.8780 - val_loss: 0.9998 - val_accuracy: 0.4200\n",
            "Epoch 8/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.5367 - accuracy: 0.8514 - val_loss: 1.1564 - val_accuracy: 0.4400\n",
            "Epoch 9/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.5266 - accuracy: 0.9069 - val_loss: 0.9906 - val_accuracy: 0.5800\n",
            "Epoch 10/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.4772 - accuracy: 0.9823 - val_loss: 0.9722 - val_accuracy: 0.5600\n",
            "Epoch 11/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.3169 - accuracy: 0.9911 - val_loss: 1.0272 - val_accuracy: 0.5400\n",
            "Epoch 12/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.1878 - accuracy: 0.9845 - val_loss: 1.0667 - val_accuracy: 0.5400\n",
            "Epoch 13/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0767 - accuracy: 0.9933 - val_loss: 1.1212 - val_accuracy: 0.6000\n",
            "Epoch 14/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0420 - accuracy: 0.9911 - val_loss: 1.6000 - val_accuracy: 0.5400\n",
            "Epoch 15/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0331 - accuracy: 0.9956 - val_loss: 1.5214 - val_accuracy: 0.5800\n",
            "Epoch 16/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0285 - accuracy: 0.9956 - val_loss: 1.4156 - val_accuracy: 0.6200\n",
            "Epoch 17/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0245 - accuracy: 0.9956 - val_loss: 1.4458 - val_accuracy: 0.6000\n",
            "Epoch 18/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0266 - accuracy: 0.9933 - val_loss: 2.2225 - val_accuracy: 0.4800\n",
            "Epoch 19/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0280 - accuracy: 0.9933 - val_loss: 2.0028 - val_accuracy: 0.5400\n",
            "Epoch 20/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 1.8529 - val_accuracy: 0.5400\n",
            "Epoch 21/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0221 - accuracy: 0.9956 - val_loss: 1.6432 - val_accuracy: 0.5800\n",
            "Epoch 22/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 1.5065 - val_accuracy: 0.6200\n",
            "Epoch 23/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0115 - accuracy: 0.9978 - val_loss: 1.5658 - val_accuracy: 0.6200\n",
            "Epoch 24/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 1.6451 - val_accuracy: 0.6000\n",
            "Epoch 25/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 1.9111 - val_accuracy: 0.5600\n",
            "Epoch 26/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0250 - accuracy: 0.9933 - val_loss: 1.8742 - val_accuracy: 0.5600\n",
            "Epoch 27/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0352 - accuracy: 0.9933 - val_loss: 1.3427 - val_accuracy: 0.6000\n",
            "Epoch 28/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0355 - accuracy: 0.9978 - val_loss: 1.2850 - val_accuracy: 0.6000\n",
            "Epoch 29/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0366 - accuracy: 0.9978 - val_loss: 1.4091 - val_accuracy: 0.6200\n",
            "Epoch 30/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0241 - accuracy: 0.9956 - val_loss: 1.8481 - val_accuracy: 0.6600\n",
            "Epoch 31/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0294 - accuracy: 0.9933 - val_loss: 2.5202 - val_accuracy: 0.5800\n",
            "Epoch 32/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0466 - accuracy: 0.9933 - val_loss: 1.1602 - val_accuracy: 0.5800\n",
            "Epoch 33/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0750 - accuracy: 0.9889 - val_loss: 1.1883 - val_accuracy: 0.5800\n",
            "Epoch 34/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0587 - accuracy: 0.9933 - val_loss: 1.2055 - val_accuracy: 0.5800\n",
            "Epoch 35/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0326 - accuracy: 0.9978 - val_loss: 1.2118 - val_accuracy: 0.6000\n",
            "Epoch 36/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0275 - accuracy: 0.9956 - val_loss: 1.2297 - val_accuracy: 0.6000\n",
            "Epoch 37/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 1.2551 - val_accuracy: 0.5800\n",
            "Epoch 38/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0203 - accuracy: 0.9956 - val_loss: 1.2818 - val_accuracy: 0.6000\n",
            "Epoch 39/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0176 - accuracy: 0.9956 - val_loss: 1.3238 - val_accuracy: 0.6200\n",
            "Epoch 40/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0177 - accuracy: 0.9933 - val_loss: 1.3531 - val_accuracy: 0.6200\n",
            "Score for fold 4: loss of 1.3531198811531067; accuracy of 62.00000047683716%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Train on 451 samples, validate on 50 samples\n",
            "Epoch 1/40\n",
            "451/451 [==============================] - 6s 13ms/step - loss: 1.0986 - accuracy: 0.2905 - val_loss: 1.0969 - val_accuracy: 0.3800\n",
            "Epoch 2/40\n",
            "451/451 [==============================] - 4s 9ms/step - loss: 1.0939 - accuracy: 0.4302 - val_loss: 1.0948 - val_accuracy: 0.4000\n",
            "Epoch 3/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 1.0853 - accuracy: 0.4412 - val_loss: 1.0897 - val_accuracy: 0.3800\n",
            "Epoch 4/40\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "451/451 [==============================] - 5s 10ms/step - loss: 1.0591 - accuracy: 0.4235 - val_loss: 1.0692 - val_accuracy: 0.4400\n",
            "Epoch 5/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 0.9793 - accuracy: 0.7228 - val_loss: 1.0620 - val_accuracy: 0.5400\n",
            "Epoch 6/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.9145 - accuracy: 0.9047 - val_loss: 1.0267 - val_accuracy: 0.5200\n",
            "Epoch 7/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 0.7924 - accuracy: 0.7650 - val_loss: 1.0069 - val_accuracy: 0.5000\n",
            "Epoch 8/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.6451 - accuracy: 0.9180 - val_loss: 0.9885 - val_accuracy: 0.5400\n",
            "Epoch 9/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.5183 - accuracy: 0.8869 - val_loss: 0.9801 - val_accuracy: 0.5600\n",
            "Epoch 10/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.3592 - accuracy: 0.9845 - val_loss: 0.9826 - val_accuracy: 0.4600\n",
            "Epoch 11/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.1694 - accuracy: 0.9734 - val_loss: 1.2577 - val_accuracy: 0.6200\n",
            "Epoch 12/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.1211 - accuracy: 0.9667 - val_loss: 1.2372 - val_accuracy: 0.6400\n",
            "Epoch 13/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0950 - accuracy: 0.9756 - val_loss: 0.8379 - val_accuracy: 0.6800\n",
            "Epoch 14/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 0.0736 - accuracy: 0.9845 - val_loss: 0.8911 - val_accuracy: 0.6200\n",
            "Epoch 15/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0421 - accuracy: 0.9933 - val_loss: 1.1292 - val_accuracy: 0.6600\n",
            "Epoch 16/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 0.0324 - accuracy: 0.9956 - val_loss: 1.2912 - val_accuracy: 0.6600\n",
            "Epoch 17/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0245 - accuracy: 0.9956 - val_loss: 1.3446 - val_accuracy: 0.6200\n",
            "Epoch 18/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 1.3895 - val_accuracy: 0.6400\n",
            "Epoch 19/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0178 - accuracy: 0.9956 - val_loss: 1.4907 - val_accuracy: 0.6400\n",
            "Epoch 20/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0197 - accuracy: 0.9956 - val_loss: 1.5840 - val_accuracy: 0.6200\n",
            "Epoch 21/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 1.5180 - val_accuracy: 0.6600\n",
            "Epoch 22/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 1.6256 - val_accuracy: 0.6200\n",
            "Epoch 23/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0124 - accuracy: 0.9933 - val_loss: 1.6493 - val_accuracy: 0.6600\n",
            "Epoch 24/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0111 - accuracy: 0.9956 - val_loss: 1.8648 - val_accuracy: 0.6200\n",
            "Epoch 25/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 1.2528 - val_accuracy: 0.5400\n",
            "Epoch 26/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0232 - accuracy: 0.9978 - val_loss: 1.1275 - val_accuracy: 0.5800\n",
            "Epoch 27/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0286 - accuracy: 0.9933 - val_loss: 1.1093 - val_accuracy: 0.6000\n",
            "Epoch 28/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 1.1358 - val_accuracy: 0.6200\n",
            "Epoch 29/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0211 - accuracy: 0.9911 - val_loss: 1.1587 - val_accuracy: 0.6000\n",
            "Epoch 30/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 1.2172 - val_accuracy: 0.6200\n",
            "Epoch 31/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0120 - accuracy: 0.9933 - val_loss: 1.2637 - val_accuracy: 0.6200\n",
            "Epoch 32/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 1.2941 - val_accuracy: 0.6600\n",
            "Epoch 33/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 1.2895 - val_accuracy: 0.6600\n",
            "Epoch 34/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0102 - accuracy: 0.9956 - val_loss: 1.3300 - val_accuracy: 0.6400\n",
            "Epoch 35/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0113 - accuracy: 0.9933 - val_loss: 1.3622 - val_accuracy: 0.6400\n",
            "Epoch 36/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0111 - accuracy: 0.9978 - val_loss: 1.3802 - val_accuracy: 0.6400\n",
            "Epoch 37/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0164 - accuracy: 0.9911 - val_loss: 1.4251 - val_accuracy: 0.6600\n",
            "Epoch 38/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 1.4525 - val_accuracy: 0.6600\n",
            "Epoch 39/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0117 - accuracy: 0.9933 - val_loss: 1.4552 - val_accuracy: 0.6400\n",
            "Epoch 40/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0099 - accuracy: 0.9978 - val_loss: 1.4742 - val_accuracy: 0.6400\n",
            "Score for fold 5: loss of 1.4742137956619263; accuracy of 63.999998569488525%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Train on 451 samples, validate on 50 samples\n",
            "Epoch 1/40\n",
            "451/451 [==============================] - 6s 13ms/step - loss: 1.0989 - accuracy: 0.3503 - val_loss: 1.0988 - val_accuracy: 0.2800\n",
            "Epoch 2/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 1.0945 - accuracy: 0.3991 - val_loss: 1.0970 - val_accuracy: 0.3000\n",
            "Epoch 3/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 1.0883 - accuracy: 0.4523 - val_loss: 1.0950 - val_accuracy: 0.2800\n",
            "Epoch 4/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 1.0703 - accuracy: 0.5211 - val_loss: 1.0833 - val_accuracy: 0.4200\n",
            "Epoch 5/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 1.0739 - accuracy: 0.6031 - val_loss: 1.0535 - val_accuracy: 0.5400\n",
            "Epoch 6/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.9999 - accuracy: 0.6763 - val_loss: 1.0608 - val_accuracy: 0.4400\n",
            "Epoch 7/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.9760 - accuracy: 0.7251 - val_loss: 1.0421 - val_accuracy: 0.4800\n",
            "Epoch 8/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.9188 - accuracy: 0.7716 - val_loss: 1.0193 - val_accuracy: 0.5600\n",
            "Epoch 9/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.8421 - accuracy: 0.7960 - val_loss: 0.9930 - val_accuracy: 0.5600\n",
            "Epoch 10/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 0.7326 - accuracy: 0.8160 - val_loss: 0.9552 - val_accuracy: 0.5400\n",
            "Epoch 11/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.5964 - accuracy: 0.8137 - val_loss: 0.9054 - val_accuracy: 0.5400\n",
            "Epoch 12/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.4613 - accuracy: 0.8115 - val_loss: 0.9225 - val_accuracy: 0.5600\n",
            "Epoch 13/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.3554 - accuracy: 0.9113 - val_loss: 0.9551 - val_accuracy: 0.5400\n",
            "Epoch 14/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.2796 - accuracy: 0.9534 - val_loss: 1.0429 - val_accuracy: 0.6000\n",
            "Epoch 15/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.2175 - accuracy: 0.9712 - val_loss: 1.0013 - val_accuracy: 0.5400\n",
            "Epoch 16/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.1462 - accuracy: 0.9933 - val_loss: 1.0006 - val_accuracy: 0.5600\n",
            "Epoch 17/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0823 - accuracy: 0.9911 - val_loss: 1.1935 - val_accuracy: 0.6400\n",
            "Epoch 18/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0414 - accuracy: 0.9933 - val_loss: 1.6347 - val_accuracy: 0.4800\n",
            "Epoch 19/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0424 - accuracy: 0.9933 - val_loss: 1.3993 - val_accuracy: 0.5400\n",
            "Epoch 20/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0402 - accuracy: 0.9933 - val_loss: 1.2579 - val_accuracy: 0.5600\n",
            "Epoch 21/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0424 - accuracy: 0.9933 - val_loss: 1.3846 - val_accuracy: 0.5400\n",
            "Epoch 22/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0238 - accuracy: 0.9956 - val_loss: 1.4796 - val_accuracy: 0.5200\n",
            "Epoch 23/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0256 - accuracy: 0.9933 - val_loss: 1.5347 - val_accuracy: 0.5000\n",
            "Epoch 24/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0207 - accuracy: 0.9956 - val_loss: 1.5203 - val_accuracy: 0.5600\n",
            "Epoch 25/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 1.6767 - val_accuracy: 0.5600\n",
            "Epoch 26/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 1.7102 - val_accuracy: 0.5200\n",
            "Epoch 27/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 1.7333 - val_accuracy: 0.5000\n",
            "Epoch 28/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 1.6143 - val_accuracy: 0.5600\n",
            "Epoch 29/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 0.0121 - accuracy: 0.9933 - val_loss: 1.6489 - val_accuracy: 0.5600\n",
            "Epoch 30/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 1.7174 - val_accuracy: 0.5800\n",
            "Epoch 31/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 1.8553 - val_accuracy: 0.5000\n",
            "Epoch 32/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0106 - accuracy: 0.9933 - val_loss: 1.7858 - val_accuracy: 0.5400\n",
            "Epoch 33/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.0171 - accuracy: 0.9933 - val_loss: 1.7929 - val_accuracy: 0.5800\n",
            "Epoch 34/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 0.0088 - accuracy: 0.9956 - val_loss: 1.9564 - val_accuracy: 0.4800\n",
            "Epoch 35/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 0.0472 - accuracy: 0.9845 - val_loss: 2.0037 - val_accuracy: 0.4000\n",
            "Epoch 36/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0301 - accuracy: 0.9956 - val_loss: 1.5632 - val_accuracy: 0.4600\n",
            "Epoch 37/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0257 - accuracy: 0.9956 - val_loss: 1.4607 - val_accuracy: 0.4600\n",
            "Epoch 38/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 0.0254 - accuracy: 0.9956 - val_loss: 1.3348 - val_accuracy: 0.4600\n",
            "Epoch 39/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 1.3869 - val_accuracy: 0.4400\n",
            "Epoch 40/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 1.4579 - val_accuracy: 0.4600\n",
            "Score for fold 6: loss of 1.4579413914680481; accuracy of 46.00000083446503%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Train on 451 samples, validate on 50 samples\n",
            "Epoch 1/40\n",
            "451/451 [==============================] - 6s 13ms/step - loss: 1.0987 - accuracy: 0.3348 - val_loss: 1.0989 - val_accuracy: 0.3800\n",
            "Epoch 2/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 1.0909 - accuracy: 0.5322 - val_loss: 1.0968 - val_accuracy: 0.5000\n",
            "Epoch 3/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 1.0796 - accuracy: 0.6319 - val_loss: 1.0932 - val_accuracy: 0.3600\n",
            "Epoch 4/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 1.0363 - accuracy: 0.6785 - val_loss: 1.0523 - val_accuracy: 0.4600\n",
            "Epoch 5/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.8838 - accuracy: 0.6075 - val_loss: 1.0166 - val_accuracy: 0.5200\n",
            "Epoch 6/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.7616 - accuracy: 0.6829 - val_loss: 0.9411 - val_accuracy: 0.5000\n",
            "Epoch 7/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.6282 - accuracy: 0.6763 - val_loss: 1.0323 - val_accuracy: 0.5200\n",
            "Epoch 8/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 0.5095 - accuracy: 0.7029 - val_loss: 0.9621 - val_accuracy: 0.4800\n",
            "Epoch 9/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.4569 - accuracy: 0.7206 - val_loss: 0.9695 - val_accuracy: 0.4600\n",
            "Epoch 10/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 0.4111 - accuracy: 0.8293 - val_loss: 1.0194 - val_accuracy: 0.5200\n",
            "Epoch 11/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.3642 - accuracy: 0.7871 - val_loss: 1.0540 - val_accuracy: 0.3600\n",
            "Epoch 12/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.3002 - accuracy: 0.9601 - val_loss: 1.5199 - val_accuracy: 0.4200\n",
            "Epoch 13/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.2359 - accuracy: 0.9712 - val_loss: 1.1530 - val_accuracy: 0.3800\n",
            "Epoch 14/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.1440 - accuracy: 0.9800 - val_loss: 1.5638 - val_accuracy: 0.3200\n",
            "Epoch 15/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.1178 - accuracy: 0.9690 - val_loss: 1.6021 - val_accuracy: 0.4400\n",
            "Epoch 16/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.1136 - accuracy: 0.9889 - val_loss: 1.5325 - val_accuracy: 0.3800\n",
            "Epoch 17/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 0.0902 - accuracy: 0.9956 - val_loss: 1.8843 - val_accuracy: 0.3200\n",
            "Epoch 18/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0555 - accuracy: 0.9933 - val_loss: 1.9597 - val_accuracy: 0.4400\n",
            "Epoch 19/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.1379 - accuracy: 0.9645 - val_loss: 1.4342 - val_accuracy: 0.4200\n",
            "Epoch 20/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.1088 - accuracy: 0.9845 - val_loss: 1.3418 - val_accuracy: 0.4200\n",
            "Epoch 21/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 0.0961 - accuracy: 0.9911 - val_loss: 1.3941 - val_accuracy: 0.4200\n",
            "Epoch 22/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0752 - accuracy: 0.9911 - val_loss: 1.5117 - val_accuracy: 0.4000\n",
            "Epoch 23/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0519 - accuracy: 0.9933 - val_loss: 1.6257 - val_accuracy: 0.4200\n",
            "Epoch 24/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0404 - accuracy: 0.9956 - val_loss: 1.7082 - val_accuracy: 0.4200\n",
            "Epoch 25/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0346 - accuracy: 0.9956 - val_loss: 1.7614 - val_accuracy: 0.4400\n",
            "Epoch 26/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0228 - accuracy: 0.9956 - val_loss: 1.8061 - val_accuracy: 0.4600\n",
            "Epoch 27/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0190 - accuracy: 0.9978 - val_loss: 1.8686 - val_accuracy: 0.4400\n",
            "Epoch 28/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 1.8868 - val_accuracy: 0.4200\n",
            "Epoch 29/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0165 - accuracy: 0.9978 - val_loss: 1.9470 - val_accuracy: 0.4400\n",
            "Epoch 30/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 2.0390 - val_accuracy: 0.4400\n",
            "Epoch 31/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0162 - accuracy: 0.9978 - val_loss: 2.1508 - val_accuracy: 0.4400\n",
            "Epoch 32/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0115 - accuracy: 0.9978 - val_loss: 2.2716 - val_accuracy: 0.4200\n",
            "Epoch 33/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0110 - accuracy: 0.9956 - val_loss: 2.3525 - val_accuracy: 0.4000\n",
            "Epoch 34/40\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0126 - accuracy: 0.9978 - val_loss: 2.3900 - val_accuracy: 0.4000\n",
            "Epoch 35/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0107 - accuracy: 0.9978 - val_loss: 2.3943 - val_accuracy: 0.4000\n",
            "Epoch 36/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 2.4143 - val_accuracy: 0.4000\n",
            "Epoch 37/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0107 - accuracy: 0.9978 - val_loss: 2.4377 - val_accuracy: 0.4200\n",
            "Epoch 38/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 2.4663 - val_accuracy: 0.4200\n",
            "Epoch 39/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 2.4932 - val_accuracy: 0.4200\n",
            "Epoch 40/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0082 - accuracy: 0.9956 - val_loss: 2.5393 - val_accuracy: 0.4200\n",
            "Score for fold 7: loss of 2.5392608880996703; accuracy of 41.999998688697815%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Train on 451 samples, validate on 50 samples\n",
            "Epoch 1/40\n",
            "451/451 [==============================] - 6s 14ms/step - loss: 1.0984 - accuracy: 0.3548 - val_loss: 1.1009 - val_accuracy: 0.2400\n",
            "Epoch 2/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 1.0935 - accuracy: 0.4723 - val_loss: 1.1005 - val_accuracy: 0.2800\n",
            "Epoch 3/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 1.0839 - accuracy: 0.5388 - val_loss: 1.1001 - val_accuracy: 0.2400\n",
            "Epoch 4/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 1.0602 - accuracy: 0.6718 - val_loss: 1.0855 - val_accuracy: 0.4000\n",
            "Epoch 5/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 0.9628 - accuracy: 0.8182 - val_loss: 2.5072 - val_accuracy: 0.1600\n",
            "Epoch 6/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 1.2106 - accuracy: 0.5410 - val_loss: 0.9670 - val_accuracy: 0.5600\n",
            "Epoch 7/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.8532 - accuracy: 0.7716 - val_loss: 0.8940 - val_accuracy: 0.5400\n",
            "Epoch 8/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.7833 - accuracy: 0.6962 - val_loss: 0.8615 - val_accuracy: 0.5200\n",
            "Epoch 9/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.6697 - accuracy: 0.8736 - val_loss: 0.8428 - val_accuracy: 0.6000\n",
            "Epoch 10/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.5693 - accuracy: 0.8869 - val_loss: 0.9244 - val_accuracy: 0.4600\n",
            "Epoch 11/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.4285 - accuracy: 0.9534 - val_loss: 0.8609 - val_accuracy: 0.6200\n",
            "Epoch 12/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.2626 - accuracy: 0.9401 - val_loss: 0.9358 - val_accuracy: 0.6000\n",
            "Epoch 13/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.1573 - accuracy: 0.9845 - val_loss: 0.9843 - val_accuracy: 0.5800\n",
            "Epoch 14/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0885 - accuracy: 0.9911 - val_loss: 1.1698 - val_accuracy: 0.6000\n",
            "Epoch 15/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0750 - accuracy: 0.9823 - val_loss: 1.1237 - val_accuracy: 0.6000\n",
            "Epoch 16/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0699 - accuracy: 0.9889 - val_loss: 1.4399 - val_accuracy: 0.5400\n",
            "Epoch 17/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0657 - accuracy: 0.9933 - val_loss: 1.3145 - val_accuracy: 0.5200\n",
            "Epoch 18/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0382 - accuracy: 0.9956 - val_loss: 1.1089 - val_accuracy: 0.6600\n",
            "Epoch 19/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0307 - accuracy: 0.9933 - val_loss: 1.2390 - val_accuracy: 0.6400\n",
            "Epoch 20/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0314 - accuracy: 0.9933 - val_loss: 1.4081 - val_accuracy: 0.6400\n",
            "Epoch 21/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.0192 - accuracy: 0.9956 - val_loss: 1.4751 - val_accuracy: 0.6400\n",
            "Epoch 22/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0303 - accuracy: 0.9933 - val_loss: 1.4594 - val_accuracy: 0.6200\n",
            "Epoch 23/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0439 - accuracy: 0.9956 - val_loss: 1.7641 - val_accuracy: 0.6000\n",
            "Epoch 24/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0501 - accuracy: 0.9956 - val_loss: 1.6473 - val_accuracy: 0.5800\n",
            "Epoch 25/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0355 - accuracy: 0.9978 - val_loss: 1.8327 - val_accuracy: 0.5600\n",
            "Epoch 26/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.0336 - accuracy: 0.9911 - val_loss: 1.5194 - val_accuracy: 0.5400\n",
            "Epoch 27/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0316 - accuracy: 0.9978 - val_loss: 1.3447 - val_accuracy: 0.5800\n",
            "Epoch 28/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.0234 - accuracy: 0.9956 - val_loss: 1.3956 - val_accuracy: 0.6400\n",
            "Epoch 29/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.0200 - accuracy: 0.9956 - val_loss: 1.3818 - val_accuracy: 0.6600\n",
            "Epoch 30/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0201 - accuracy: 0.9956 - val_loss: 1.4230 - val_accuracy: 0.6200\n",
            "Epoch 31/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 1.5128 - val_accuracy: 0.6200\n",
            "Epoch 32/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0181 - accuracy: 0.9956 - val_loss: 1.6377 - val_accuracy: 0.6200\n",
            "Epoch 33/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0181 - accuracy: 0.9956 - val_loss: 1.7907 - val_accuracy: 0.6200\n",
            "Epoch 34/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0155 - accuracy: 0.9933 - val_loss: 1.8828 - val_accuracy: 0.6400\n",
            "Epoch 35/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 1.9719 - val_accuracy: 0.6400\n",
            "Epoch 36/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0127 - accuracy: 0.9933 - val_loss: 2.0547 - val_accuracy: 0.6200\n",
            "Epoch 37/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 2.1102 - val_accuracy: 0.6200\n",
            "Epoch 38/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0089 - accuracy: 0.9978 - val_loss: 2.1680 - val_accuracy: 0.6000\n",
            "Epoch 39/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0106 - accuracy: 0.9956 - val_loss: 2.2019 - val_accuracy: 0.6000\n",
            "Epoch 40/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0094 - accuracy: 0.9956 - val_loss: 2.2233 - val_accuracy: 0.6200\n",
            "Score for fold 8: loss of 2.2233032989501953; accuracy of 62.00000047683716%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Train on 451 samples, validate on 50 samples\n",
            "Epoch 1/40\n",
            "451/451 [==============================] - 6s 14ms/step - loss: 1.0991 - accuracy: 0.3193 - val_loss: 1.1002 - val_accuracy: 0.2400\n",
            "Epoch 2/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 1.0944 - accuracy: 0.4457 - val_loss: 1.0987 - val_accuracy: 0.3200\n",
            "Epoch 3/40\n",
            "451/451 [==============================] - 4s 10ms/step - loss: 1.0867 - accuracy: 0.5455 - val_loss: 1.0977 - val_accuracy: 0.3600\n",
            "Epoch 4/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 1.0670 - accuracy: 0.6497 - val_loss: 1.0882 - val_accuracy: 0.3800\n",
            "Epoch 5/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.9956 - accuracy: 0.7960 - val_loss: 1.0401 - val_accuracy: 0.4200\n",
            "Epoch 6/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.8500 - accuracy: 0.6918 - val_loss: 1.0729 - val_accuracy: 0.4800\n",
            "Epoch 7/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.7224 - accuracy: 0.7738 - val_loss: 0.9587 - val_accuracy: 0.6400\n",
            "Epoch 8/40\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "451/451 [==============================] - 5s 11ms/step - loss: 0.5826 - accuracy: 0.7162 - val_loss: 1.1390 - val_accuracy: 0.5800\n",
            "Epoch 9/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.4877 - accuracy: 0.7827 - val_loss: 1.1562 - val_accuracy: 0.6400\n",
            "Epoch 10/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.3800 - accuracy: 0.8714 - val_loss: 1.1526 - val_accuracy: 0.4600\n",
            "Epoch 11/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.2603 - accuracy: 0.9468 - val_loss: 1.1120 - val_accuracy: 0.6400\n",
            "Epoch 12/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.2112 - accuracy: 0.9357 - val_loss: 1.0149 - val_accuracy: 0.6400\n",
            "Epoch 13/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.1503 - accuracy: 0.9889 - val_loss: 1.1145 - val_accuracy: 0.5800\n",
            "Epoch 14/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0707 - accuracy: 0.9911 - val_loss: 1.3522 - val_accuracy: 0.6400\n",
            "Epoch 15/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0472 - accuracy: 0.9911 - val_loss: 1.7586 - val_accuracy: 0.6000\n",
            "Epoch 16/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0324 - accuracy: 0.9978 - val_loss: 1.6147 - val_accuracy: 0.6200\n",
            "Epoch 17/40\n",
            "451/451 [==============================] - 6s 12ms/step - loss: 0.0161 - accuracy: 0.9978 - val_loss: 1.6557 - val_accuracy: 0.6600\n",
            "Epoch 18/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 1.7114 - val_accuracy: 0.6200\n",
            "Epoch 19/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0116 - accuracy: 0.9978 - val_loss: 1.8887 - val_accuracy: 0.6400\n",
            "Epoch 20/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0098 - accuracy: 0.9978 - val_loss: 1.9358 - val_accuracy: 0.6400\n",
            "Epoch 21/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0138 - accuracy: 0.9978 - val_loss: 1.9831 - val_accuracy: 0.6600\n",
            "Epoch 22/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0090 - accuracy: 0.9978 - val_loss: 1.9744 - val_accuracy: 0.6600\n",
            "Epoch 23/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0155 - accuracy: 0.9978 - val_loss: 1.9467 - val_accuracy: 0.6800\n",
            "Epoch 24/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 1.9423 - val_accuracy: 0.6800\n",
            "Epoch 25/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0118 - accuracy: 0.9978 - val_loss: 1.9659 - val_accuracy: 0.7000\n",
            "Epoch 26/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0074 - accuracy: 0.9956 - val_loss: 2.0163 - val_accuracy: 0.6600\n",
            "Epoch 27/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0103 - accuracy: 0.9978 - val_loss: 2.0733 - val_accuracy: 0.6600\n",
            "Epoch 28/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.0747 - val_accuracy: 0.6600\n",
            "Epoch 29/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 2.0757 - val_accuracy: 0.6600\n",
            "Epoch 30/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 2.1602 - val_accuracy: 0.6600\n",
            "Epoch 31/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0128 - accuracy: 0.9978 - val_loss: 2.3047 - val_accuracy: 0.6200\n",
            "Epoch 32/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0101 - accuracy: 0.9978 - val_loss: 2.1358 - val_accuracy: 0.6600\n",
            "Epoch 33/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0085 - accuracy: 0.9978 - val_loss: 2.0674 - val_accuracy: 0.6800\n",
            "Epoch 34/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 2.0662 - val_accuracy: 0.7000\n",
            "Epoch 35/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 2.2066 - val_accuracy: 0.6800\n",
            "Epoch 36/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0070 - accuracy: 0.9956 - val_loss: 2.2341 - val_accuracy: 0.6800\n",
            "Epoch 37/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0050 - accuracy: 0.9978 - val_loss: 2.2035 - val_accuracy: 0.6800\n",
            "Epoch 38/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 2.1897 - val_accuracy: 0.6800\n",
            "Epoch 39/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.0066 - accuracy: 0.9956 - val_loss: 2.3120 - val_accuracy: 0.6800\n",
            "Epoch 40/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0084 - accuracy: 0.9956 - val_loss: 2.3305 - val_accuracy: 0.6600\n",
            "Score for fold 9: loss of 2.3305302810668946; accuracy of 66.00000262260437%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 10 ...\n",
            "Train on 451 samples, validate on 50 samples\n",
            "Epoch 1/40\n",
            "451/451 [==============================] - 7s 15ms/step - loss: 1.0989 - accuracy: 0.3215 - val_loss: 1.0981 - val_accuracy: 0.3000\n",
            "Epoch 2/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 1.0939 - accuracy: 0.4324 - val_loss: 1.0990 - val_accuracy: 0.2400\n",
            "Epoch 3/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 1.0859 - accuracy: 0.4191 - val_loss: 1.0984 - val_accuracy: 0.2400\n",
            "Epoch 4/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 1.0692 - accuracy: 0.5499 - val_loss: 1.0887 - val_accuracy: 0.4000\n",
            "Epoch 5/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 1.0269 - accuracy: 0.6940 - val_loss: 1.0524 - val_accuracy: 0.4800\n",
            "Epoch 6/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.8891 - accuracy: 0.7938 - val_loss: 1.2916 - val_accuracy: 0.5200\n",
            "Epoch 7/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.8421 - accuracy: 0.6896 - val_loss: 0.9572 - val_accuracy: 0.6400\n",
            "Epoch 8/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.7020 - accuracy: 0.7849 - val_loss: 0.8732 - val_accuracy: 0.6600\n",
            "Epoch 9/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.5646 - accuracy: 0.8071 - val_loss: 0.9179 - val_accuracy: 0.6400\n",
            "Epoch 10/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.4368 - accuracy: 0.8248 - val_loss: 0.9170 - val_accuracy: 0.5600\n",
            "Epoch 11/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.2592 - accuracy: 0.9867 - val_loss: 1.1535 - val_accuracy: 0.6000\n",
            "Epoch 12/40\n",
            "451/451 [==============================] - 5s 10ms/step - loss: 0.2533 - accuracy: 0.9180 - val_loss: 1.2902 - val_accuracy: 0.6200\n",
            "Epoch 13/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.1255 - accuracy: 0.9800 - val_loss: 1.1009 - val_accuracy: 0.5400\n",
            "Epoch 14/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.1194 - accuracy: 0.9911 - val_loss: 1.2317 - val_accuracy: 0.5200\n",
            "Epoch 15/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0679 - accuracy: 0.9956 - val_loss: 1.3411 - val_accuracy: 0.5200\n",
            "Epoch 16/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 1.5143 - val_accuracy: 0.5400\n",
            "Epoch 17/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.6256 - val_accuracy: 0.5400\n",
            "Epoch 18/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.7419 - val_accuracy: 0.5800\n",
            "Epoch 19/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.8558 - val_accuracy: 0.5800\n",
            "Epoch 20/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.9572 - val_accuracy: 0.5600\n",
            "Epoch 21/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.0507 - val_accuracy: 0.5800\n",
            "Epoch 22/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.1201 - val_accuracy: 0.5800\n",
            "Epoch 23/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.1684 - val_accuracy: 0.5600\n",
            "Epoch 24/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.2236 - val_accuracy: 0.5600\n",
            "Epoch 25/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.2100 - val_accuracy: 0.6200\n",
            "Epoch 26/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.2486 - val_accuracy: 0.6200\n",
            "Epoch 27/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.2941 - val_accuracy: 0.6000\n",
            "Epoch 28/40\n",
            "451/451 [==============================] - 6s 14ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.3494 - val_accuracy: 0.6000\n",
            "Epoch 29/40\n",
            "451/451 [==============================] - 6s 12ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.3999 - val_accuracy: 0.6000\n",
            "Epoch 30/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.3973 - val_accuracy: 0.6000\n",
            "Epoch 31/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.4549 - val_accuracy: 0.6000\n",
            "Epoch 32/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5350 - val_accuracy: 0.5800\n",
            "Epoch 33/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6084 - val_accuracy: 0.5800\n",
            "Epoch 34/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.6915 - val_accuracy: 0.5800\n",
            "Epoch 35/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7863 - val_accuracy: 0.5800\n",
            "Epoch 36/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6725 - val_accuracy: 0.5800\n",
            "Epoch 37/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6140 - val_accuracy: 0.5200\n",
            "Epoch 38/40\n",
            "451/451 [==============================] - 5s 11ms/step - loss: 0.0134 - accuracy: 0.9978 - val_loss: 2.0963 - val_accuracy: 0.5000\n",
            "Epoch 39/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.9741 - val_accuracy: 0.5200\n",
            "Epoch 40/40\n",
            "451/451 [==============================] - 5s 12ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 2.1316 - val_accuracy: 0.4200\n",
            "Score for fold 10: loss of 2.131583027839661; accuracy of 41.999998688697815%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 1.628326647421893 - Accuracy: 49.01960790157318%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 1.3687478399276733 - Accuracy: 57.999998331069946%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 1.7021769285202026 - Accuracy: 68.00000071525574%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 1.3531198811531067 - Accuracy: 62.00000047683716%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.4742137956619263 - Accuracy: 63.999998569488525%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 6 - Loss: 1.4579413914680481 - Accuracy: 46.00000083446503%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 7 - Loss: 2.5392608880996703 - Accuracy: 41.999998688697815%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 8 - Loss: 2.2233032989501953 - Accuracy: 62.00000047683716%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 9 - Loss: 2.3305302810668946 - Accuracy: 66.00000262260437%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 10 - Loss: 2.131583027839661 - Accuracy: 41.999998688697815%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 55.90196073055267 (+- 9.615767598617875)\n",
            "> Loss: 1.8209203980109272\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U-JPhsNsK84"
      },
      "source": [
        "### Grafik"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlYw01dIsK84",
        "outputId": "30234802-9ff6-4ffc-8521-d80744b92080"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plot = '3'\n",
        "\n",
        "plt.title('Accuracy')\n",
        "plt.plot(plot_acc_per_fold[plot], label='train')\n",
        "plt.plot(plot_val_acc_per_fold[plot], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4bXcaLosK84"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}